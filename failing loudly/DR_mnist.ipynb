{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eeea4e-4367-4d27-a82e-ac37f11ed580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install keras-resnet==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2955b91-b4e2-40b0-92fb-9e23ea639fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahzadkhoshlessan/miniconda3/envs/FSDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mahzadkhoshlessan/miniconda3/envs/FSDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mahzadkhoshlessan/miniconda3/envs/FSDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mahzadkhoshlessan/miniconda3/envs/FSDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mahzadkhoshlessan/miniconda3/envs/FSDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mahzadkhoshlessan/miniconda3/envs/FSDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "import keras\n",
    "import tempfile\n",
    "import keras.models\n",
    "\n",
    "from keras import backend as K \n",
    "from shift_detector import *\n",
    "from shift_locator import *\n",
    "from shift_applicator import *\n",
    "from data_utils import *\n",
    "from shared_utils import *\n",
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b2026a-cacb-4418-9100-bac35487ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahzadkhoshlessan/miniconda3/envs/FSDL/lib/python3.6/site-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Support for setting the 'text.latex.preamble' or 'pgf.preamble' rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rc('font',**{'family':'serif','serif':['Times']})\n",
    "rc('text', usetex=True)\n",
    "rc('axes', labelsize=22)\n",
    "rc('xtick', labelsize=22)\n",
    "rc('ytick', labelsize=22)\n",
    "rc('legend', fontsize=13)\n",
    "\n",
    "mpl.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']\n",
    "\n",
    "\n",
    "def clamp(val, minimum=0, maximum=255):\n",
    "    if val < minimum:\n",
    "        return minimum\n",
    "    if val > maximum:\n",
    "        return maximum\n",
    "    return val\n",
    "\n",
    "\n",
    "def colorscale(hexstr, scalefactor):\n",
    "    hexstr = hexstr.strip('#')\n",
    "\n",
    "    if scalefactor < 0 or len(hexstr) != 6:\n",
    "        return hexstr\n",
    "\n",
    "    r, g, b = int(hexstr[:2], 16), int(hexstr[2:4], 16), int(hexstr[4:], 16)\n",
    "\n",
    "    r = clamp(r * scalefactor)\n",
    "    g = clamp(g * scalefactor)\n",
    "    b = clamp(b * scalefactor)\n",
    "\n",
    "    return \"#%02x%02x%02x\" % (int(r), int(g), int(b))\n",
    "\n",
    "\n",
    "def errorfill(x, y, yerr, color=None, alpha_fill=0.2, ax=None, fmt='-o', label=None):\n",
    "    ax = ax if ax is not None else plt.gca()\n",
    "    if color is None:\n",
    "        color = next(ax._get_lines.prop_cycler)['color']\n",
    "    if np.isscalar(yerr) or len(yerr) == len(y):\n",
    "        ymin = y - yerr\n",
    "        ymax = y + yerr\n",
    "    elif len(yerr) == 2:\n",
    "        ymin, ymax = yerr\n",
    "    ax.semilogx(x, y, fmt, color=color, label=label)\n",
    "    ax.fill_between(x, np.clip(ymax, 0, 1), np.clip(ymin, 0, 1), color=color, alpha=alpha_fill)\n",
    "\n",
    "\n",
    "def make_keras_picklable():\n",
    "    def __getstate__(self):\n",
    "        model_str = \"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            keras.models.save_model(self, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            model = keras.models.load_model(fd.name)\n",
    "        self.__dict__ = model.__dict__\n",
    "\n",
    "\n",
    "    cls = keras.models.Model\n",
    "    cls.__getstate__ = __getstate__\n",
    "    cls.__setstate__ = __setstate__\n",
    "\n",
    "\n",
    "linestyles = ['-', '-.', '--', ':']\n",
    "brightness = [1.25, 1.0, 0.75, 0.5]\n",
    "format = ['-o', '-h', '-p', '-s', '-D', '-<', '->', '-X']\n",
    "markers = ['o', 'h', 'p', 's', 'D', '<', '>', 'X']\n",
    "colors_old = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
    "              '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "              '#bcbd22', '#17becf']\n",
    "colors = ['#2196f3', '#f44336', '#9c27b0', '#64dd17', '#009688', '#ff9800', '#795548', '#607d8b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04931822-edde-4a73-9718-d5904efb55d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_keras_picklable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d543ec-9fa9-4e0c-8ce5-bd2fc121d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datset = 'mnist'\n",
    "test_type = 'univ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36e4fd9-b044-4308-842d-c63ade40e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './paper_results/'\n",
    "path += test_type + '/'\n",
    "path += datset + '_'\n",
    "path += 'adversarial_shift' + '/'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d09cd5e5-9584-4cf2-b2f4-b34f3be3af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_techniques = [DimensionalityReduction.NoRed.value, DimensionalityReduction.PCA.value, \n",
    "                 DimensionalityReduction.UAE.value, DimensionalityReduction.TAE.value] \n",
    "# dr_techniques = [DimensionalityReduction.NoRed.value, DimensionalityReduction.PCA.value, DimensionalityReduction.SRP.value, \n",
    "#                  DimensionalityReduction.UAE.value, DimensionalityReduction.TAE.value, DimensionalityReduction.BBSDs.value, \n",
    "#                  DimensionalityReduction.BBSDh.value] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed61e1e9-e0af-4df5-b09f-e706c4b095e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_techniques_plot = dr_techniques.copy()\n",
    "dr_techniques_plot.append(DimensionalityReduction.Classif.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec8e217-e68e-41ab-9e7b-cbbc7b9feb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_types = [td.value for td in TestDimensionality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ed660a5-965c-49bc-8649-c735c45c6e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af0bda4-d28a-406e-bab7-6a5ba98ba3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_tests = [OnedimensionalTest.KS.value]\n",
    "md_tests = []\n",
    "samples = [10 , 20, 50, 100, 200, 500, 1000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ad59033-08d9-493a-b244-a1fd05b07de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_samples = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509ed67e-8070-4ca8-8f04-799e8dc26247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of random runs to average results over.\n",
    "random_runs = 1\n",
    "\n",
    "# Significance level.\n",
    "sign_level = 0.05\n",
    "\n",
    "# Whether to calculate accuracy for malignancy quantification.\n",
    "calc_acc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67a118cf-886d-4586-9fb5-d438c0fdf337",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = ['adversarial_shift_0.1',\n",
    "          'adversarial_shift_0.5',\n",
    "          'adversarial_shift_1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5dc6231-33b4-4079-8287-dcbcdce4c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores p-values for all experiments of a shift class.\n",
    "samples_shifts_rands_dr_tech = np.ones((len(samples), len(shifts), random_runs, len(dr_techniques_plot))) * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d95fe3-7d3a-4616-b44f-a3b0190ffb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_dim = -1\n",
    "red_models = [None] * len(DimensionalityReduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e777e601-13a3-434e-98a8-54ba5bd5b21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./paper_results/univ/mnist_adversarial_shift/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33d71c1a-043c-4cda-85fe-547c766b528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random run 0\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "Small adversarial Shift\n",
      "Sample 10\n",
      "NoRed\n",
      "None\n",
      "(10, 784)\n",
      "(10, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(10, 32)\n",
      "(10, 28, 28) (10, 28, 28)\n",
      "UAE\n",
      "Hello There\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(10, 28, 28, 1)\n",
      "(10, 28, 28)\n",
      "TAE\n",
      "Hello There\n",
      "Train on 50000 samples, validate on 10 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.4053 - val_loss: 0.4168\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.3861 - val_loss: 0.4052\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.3741 - val_loss: 0.3933\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.2741 - val_loss: 0.2397\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.2030 - val_loss: 0.2135\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1901 - val_loss: 0.2012\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1828 - val_loss: 0.1968\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.1773 - val_loss: 0.1865\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.1734 - val_loss: 0.1883\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.1703 - val_loss: 0.1800\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.1681 - val_loss: 0.1776\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 0.1663 - val_loss: 0.1752\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 75s 2ms/step - loss: 0.1648 - val_loss: 0.1737\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.1634 - val_loss: 0.1725\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.1619 - val_loss: 0.1700\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.1610 - val_loss: 0.1710\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.1594 - val_loss: 0.1699\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.1587 - val_loss: 0.1664\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.1576 - val_loss: 0.1652\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.1565 - val_loss: 0.1638\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.1556 - val_loss: 0.1639\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1547 - val_loss: 0.1626\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1539 - val_loss: 0.1635\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.1532 - val_loss: 0.1616\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1526 - val_loss: 0.1611\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1520 - val_loss: 0.1608\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1514 - val_loss: 0.1593\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1508 - val_loss: 0.1591\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1503 - val_loss: 0.1591\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.1498 - val_loss: 0.1572\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 0.1489 - val_loss: 0.1585\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1488 - val_loss: 0.1564\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1480 - val_loss: 0.1565\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1478 - val_loss: 0.1559\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1472 - val_loss: 0.1547\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1469 - val_loss: 0.1553\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1464 - val_loss: 0.1545\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1459 - val_loss: 0.1537\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1456 - val_loss: 0.1531\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.1452 - val_loss: 0.1522\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 627s 13ms/step - loss: 0.1450 - val_loss: 0.1525\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 89s 2ms/step - loss: 0.1447 - val_loss: 0.1524\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 0.1443 - val_loss: 0.1519\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 86s 2ms/step - loss: 0.1437 - val_loss: 0.1510\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1437 - val_loss: 0.1508\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.1433 - val_loss: 0.1539\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1427 - val_loss: 0.1518\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1425 - val_loss: 0.1504\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1421 - val_loss: 0.1504\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1418 - val_loss: 0.1496\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1418 - val_loss: 0.1496\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1413 - val_loss: 0.1494\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.1411 - val_loss: 0.1483\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1409 - val_loss: 0.1496\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1405 - val_loss: 0.1503\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1401 - val_loss: 0.1495\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1401 - val_loss: 0.1488\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1397 - val_loss: 0.1491\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1395 - val_loss: 0.1485\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1393 - val_loss: 0.1485\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1391 - val_loss: 0.1499\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1387 - val_loss: 0.1488\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.1387 - val_loss: 0.1511\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1385 - val_loss: 0.1496\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1385 - val_loss: 0.1500\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1380 - val_loss: 0.1481\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1378 - val_loss: 0.1501\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1378 - val_loss: 0.1480\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.1376 - val_loss: 0.1477\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1373 - val_loss: 0.1474\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1373 - val_loss: 0.1483\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1371 - val_loss: 0.1481\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1369 - val_loss: 0.1476\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1368 - val_loss: 0.1473\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1369 - val_loss: 0.1481\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1366 - val_loss: 0.1474\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1365 - val_loss: 0.1477\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1365 - val_loss: 0.1475\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1362 - val_loss: 0.1473\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1361 - val_loss: 0.1469\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1359 - val_loss: 0.1471\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1362 - val_loss: 0.1472\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1357 - val_loss: 0.1495\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1358 - val_loss: 0.1466\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.1356 - val_loss: 0.1480\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1355 - val_loss: 0.1472\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1352 - val_loss: 0.1471\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1357 - val_loss: 0.1466\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1350 - val_loss: 0.1470\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1350 - val_loss: 0.1458\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1350 - val_loss: 0.1461\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1352 - val_loss: 0.1472\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1348 - val_loss: 0.1464\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1345 - val_loss: 0.1452\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1344 - val_loss: 0.1499\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1345 - val_loss: 0.1451\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1345 - val_loss: 0.1469\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1342 - val_loss: 0.1454\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1342 - val_loss: 0.1449\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1341 - val_loss: 0.1460\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 0.1341 - val_loss: 0.1453\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1339 - val_loss: 0.1453\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1339 - val_loss: 0.1455\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1341 - val_loss: 0.1439\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1335 - val_loss: 0.1470\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1334 - val_loss: 0.1439\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.1333 - val_loss: 0.1442\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.1332 - val_loss: 0.1438\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.1333 - val_loss: 0.1436\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.1332 - val_loss: 0.1434\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.1331 - val_loss: 0.1433\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.1327 - val_loss: 0.1437\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.1331 - val_loss: 0.1442\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.1328 - val_loss: 0.1429\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1328 - val_loss: 0.1448\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1325 - val_loss: 0.1428\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1325 - val_loss: 0.1431\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1323 - val_loss: 0.1437\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1324 - val_loss: 0.1446\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1322 - val_loss: 0.1425\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.1322 - val_loss: 0.1420\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.1320 - val_loss: 0.1419\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.1319 - val_loss: 0.1421\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.1317 - val_loss: 0.1419\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.1316 - val_loss: 0.1422\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.1318 - val_loss: 0.1424\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 84s 2ms/step - loss: 0.1316 - val_loss: 0.1412\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1317 - val_loss: 0.1414\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1314 - val_loss: 0.1426\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1313 - val_loss: 0.1411\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1311 - val_loss: 0.1410\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1309 - val_loss: 0.1411\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1312 - val_loss: 0.1411\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1309 - val_loss: 0.1408\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1308 - val_loss: 0.1402\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1306 - val_loss: 0.1414\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1308 - val_loss: 0.1427\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1307 - val_loss: 0.1408\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1305 - val_loss: 0.1406\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1305 - val_loss: 0.1399\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1302 - val_loss: 0.1428\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1302 - val_loss: 0.1396\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1303 - val_loss: 0.1398\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1303 - val_loss: 0.1427\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 849s 17ms/step - loss: 0.1302 - val_loss: 0.1397\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1299 - val_loss: 0.1390\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1298 - val_loss: 0.1391\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 22796s 456ms/step - loss: 0.1298 - val_loss: 0.1388\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 5487s 110ms/step - loss: 0.1297 - val_loss: 0.1386\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1295 - val_loss: 0.1398\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1297 - val_loss: 0.1386\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 2567s 51ms/step - loss: 0.1297 - val_loss: 0.1385\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.1296 - val_loss: 0.1384\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.1294 - val_loss: 0.1394\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1299 - val_loss: 0.1405\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1291 - val_loss: 0.1380\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1296 - val_loss: 0.1375\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1289 - val_loss: 0.1377\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 2725s 55ms/step - loss: 0.1291 - val_loss: 0.1389\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 122s 2ms/step - loss: 0.1291 - val_loss: 0.1378\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.1292 - val_loss: 0.1377\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.1287 - val_loss: 0.1380\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.1289 - val_loss: 0.1375\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1287 - val_loss: 0.1374\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1287 - val_loss: 0.1377\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1286 - val_loss: 0.1373\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1284 - val_loss: 0.1368\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1284 - val_loss: 0.1380\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1283 - val_loss: 0.1373\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1288 - val_loss: 0.1368\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1284 - val_loss: 0.1373\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1280 - val_loss: 0.1367\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1281 - val_loss: 0.1364\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1279 - val_loss: 0.1363\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1279 - val_loss: 0.1371\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1280 - val_loss: 0.1363\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1279 - val_loss: 0.1364\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1278 - val_loss: 0.1365\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1279 - val_loss: 0.1355\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1275 - val_loss: 0.1357\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1275 - val_loss: 0.1395\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.1278 - val_loss: 0.1370\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1273 - val_loss: 0.1377\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 75s 2ms/step - loss: 0.1273 - val_loss: 0.1361\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1271 - val_loss: 0.1365\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1270 - val_loss: 0.1360\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1270 - val_loss: 0.1375\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1269 - val_loss: 0.1359\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1269 - val_loss: 0.1360\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.1269 - val_loss: 0.1369\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.1268 - val_loss: 0.1366\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 847s 17ms/step - loss: 0.1267 - val_loss: 0.1361\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.1266 - val_loss: 0.1367\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.1264 - val_loss: 0.1377\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1262 - val_loss: 0.1355\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1263 - val_loss: 0.1357\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1262 - val_loss: 0.1352\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1259 - val_loss: 0.1356\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1258 - val_loss: 0.1360\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1258 - val_loss: 0.1352\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(10, 28, 28, 1)\n",
      "(10, 28, 28)\n",
      "Sample 20\n",
      "NoRed\n",
      "None\n",
      "(20, 784)\n",
      "(20, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(20, 32)\n",
      "(20, 28, 28) (20, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(20, 28, 28, 1)\n",
      "(20, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(20, 28, 28, 1)\n",
      "(20, 28, 28)\n",
      "Sample 50\n",
      "NoRed\n",
      "None\n",
      "(50, 784)\n",
      "(50, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(50, 32)\n",
      "(50, 28, 28) (50, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(50, 28, 28, 1)\n",
      "(50, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(50, 28, 28, 1)\n",
      "(50, 28, 28)\n",
      "Sample 100\n",
      "NoRed\n",
      "None\n",
      "(100, 784)\n",
      "(100, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(100, 32)\n",
      "(100, 28, 28) (100, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(100, 28, 28, 1)\n",
      "(100, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(100, 28, 28, 1)\n",
      "(100, 28, 28)\n",
      "Sample 200\n",
      "NoRed\n",
      "None\n",
      "(200, 784)\n",
      "(200, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(200, 32)\n",
      "(200, 28, 28) (200, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(200, 28, 28, 1)\n",
      "(200, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(200, 28, 28, 1)\n",
      "(200, 28, 28)\n",
      "Sample 500\n",
      "NoRed\n",
      "None\n",
      "(500, 784)\n",
      "(500, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(500, 32)\n",
      "(500, 28, 28) (500, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(500, 28, 28, 1)\n",
      "(500, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(500, 28, 28, 1)\n",
      "(500, 28, 28)\n",
      "Sample 1000\n",
      "NoRed\n",
      "None\n",
      "(1000, 784)\n",
      "(1000, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(1000, 32)\n",
      "(1000, 28, 28) (1000, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(1000, 28, 28, 1)\n",
      "(1000, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(1000, 28, 28, 1)\n",
      "(1000, 28, 28)\n",
      "Sample 10000\n",
      "NoRed\n",
      "None\n",
      "(10000, 784)\n",
      "(10000, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(10000, 32)\n",
      "(10000, 28, 28) (10000, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 28, 28)\n",
      "Random run 0\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "Medium adversarial Shift\n",
      "Sample 10\n",
      "NoRed\n",
      "None\n",
      "(10, 784)\n",
      "(10, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(10, 32)\n",
      "(10, 28, 28) (10, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(10, 28, 28, 1)\n",
      "(10, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(10, 28, 28, 1)\n",
      "(10, 28, 28)\n",
      "Sample 20\n",
      "NoRed\n",
      "None\n",
      "(20, 784)\n",
      "(20, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(20, 32)\n",
      "(20, 28, 28) (20, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(20, 28, 28, 1)\n",
      "(20, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(20, 28, 28, 1)\n",
      "(20, 28, 28)\n",
      "Sample 50\n",
      "NoRed\n",
      "None\n",
      "(50, 784)\n",
      "(50, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(50, 32)\n",
      "(50, 28, 28) (50, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(50, 28, 28, 1)\n",
      "(50, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(50, 28, 28, 1)\n",
      "(50, 28, 28)\n",
      "Sample 100\n",
      "NoRed\n",
      "None\n",
      "(100, 784)\n",
      "(100, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(100, 32)\n",
      "(100, 28, 28) (100, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(100, 28, 28, 1)\n",
      "(100, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(100, 28, 28, 1)\n",
      "(100, 28, 28)\n",
      "Sample 200\n",
      "NoRed\n",
      "None\n",
      "(200, 784)\n",
      "(200, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(200, 32)\n",
      "(200, 28, 28) (200, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(200, 28, 28, 1)\n",
      "(200, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(200, 28, 28, 1)\n",
      "(200, 28, 28)\n",
      "Sample 500\n",
      "NoRed\n",
      "None\n",
      "(500, 784)\n",
      "(500, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(500, 32)\n",
      "(500, 28, 28) (500, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(500, 28, 28, 1)\n",
      "(500, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(500, 28, 28, 1)\n",
      "(500, 28, 28)\n",
      "Sample 1000\n",
      "NoRed\n",
      "None\n",
      "(1000, 784)\n",
      "(1000, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(1000, 32)\n",
      "(1000, 28, 28) (1000, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(1000, 28, 28, 1)\n",
      "(1000, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(1000, 28, 28, 1)\n",
      "(1000, 28, 28)\n",
      "Sample 10000\n",
      "NoRed\n",
      "None\n",
      "(10000, 784)\n",
      "(10000, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(10000, 32)\n",
      "(10000, 28, 28) (10000, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 28, 28)\n",
      "Random run 0\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "Large adversarial shift\n",
      "Sample 10\n",
      "NoRed\n",
      "None\n",
      "(10, 784)\n",
      "(10, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(10, 32)\n",
      "(10, 28, 28) (10, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(10, 28, 28, 1)\n",
      "(10, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(10, 28, 28, 1)\n",
      "(10, 28, 28)\n",
      "Sample 20\n",
      "NoRed\n",
      "None\n",
      "(20, 784)\n",
      "(20, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(20, 32)\n",
      "(20, 28, 28) (20, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(20, 28, 28, 1)\n",
      "(20, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(20, 28, 28, 1)\n",
      "(20, 28, 28)\n",
      "Sample 50\n",
      "NoRed\n",
      "None\n",
      "(50, 784)\n",
      "(50, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(50, 32)\n",
      "(50, 28, 28) (50, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(50, 28, 28, 1)\n",
      "(50, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(50, 28, 28, 1)\n",
      "(50, 28, 28)\n",
      "Sample 100\n",
      "NoRed\n",
      "None\n",
      "(100, 784)\n",
      "(100, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(100, 32)\n",
      "(100, 28, 28) (100, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(100, 28, 28, 1)\n",
      "(100, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(100, 28, 28, 1)\n",
      "(100, 28, 28)\n",
      "Sample 200\n",
      "NoRed\n",
      "None\n",
      "(200, 784)\n",
      "(200, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(200, 32)\n",
      "(200, 28, 28) (200, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(200, 28, 28, 1)\n",
      "(200, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(200, 28, 28, 1)\n",
      "(200, 28, 28)\n",
      "Sample 500\n",
      "NoRed\n",
      "None\n",
      "(500, 784)\n",
      "(500, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(500, 32)\n",
      "(500, 28, 28) (500, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(500, 28, 28, 1)\n",
      "(500, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(500, 28, 28, 1)\n",
      "(500, 28, 28)\n",
      "Sample 1000\n",
      "NoRed\n",
      "None\n",
      "(1000, 784)\n",
      "(1000, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(1000, 32)\n",
      "(1000, 28, 28) (1000, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(1000, 28, 28, 1)\n",
      "(1000, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(1000, 28, 28, 1)\n",
      "(1000, 28, 28)\n",
      "Sample 10000\n",
      "NoRed\n",
      "None\n",
      "(10000, 784)\n",
      "(10000, 28, 28)\n",
      "PCA\n",
      "PCA(n_components=32)\n",
      "(10000, 32)\n",
      "(10000, 28, 28) (10000, 28, 28)\n",
      "UAE\n",
      "<keras.engine.training.Model object at 0x7fcda250b0b8>\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 28, 28)\n",
      "TAE\n",
      "<keras.engine.training.Model object at 0x7fcda25ac7f0>\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "for shift_idx, shift in enumerate(shifts):\n",
    "    shift_path = path + shift + '/'\n",
    "    if not os.path.exists(shift_path):\n",
    "        os.makedirs(shift_path)\n",
    "        \n",
    "    # Stores p-values for a single shift.\n",
    "    rand_run_p_vals = np.ones((len(samples), len(dr_techniques_plot), random_runs)) * (-1)\n",
    "    \n",
    "    # Stores accuracy values for malignancy detection.\n",
    "    val_accs = np.ones((random_runs, len(samples))) * (-1)\n",
    "    te_accs = np.ones((random_runs, len(samples))) * (-1)\n",
    "    dcl_accs = np.ones((len(samples), random_runs)) * (-1)\n",
    "    \n",
    "    # Average over a few random runs to quantify robustness.\n",
    "    for rand_run in range(random_runs):\n",
    "        print(\"Random run %s\" % rand_run)\n",
    "\n",
    "        rand_run_path = shift_path + str(rand_run) + '/'\n",
    "        if not os.path.exists(rand_run_path):\n",
    "            os.makedirs(rand_run_path)\n",
    "\n",
    "        np.random.seed(rand_run)\n",
    "        tf.set_random_seed(rand_run)\n",
    "\n",
    "        # Load data.\n",
    "        (X_tr_orig, y_tr_orig), (X_val_orig, y_val_orig), (X_te_orig, y_te_orig), orig_dims, nb_classes = \\\n",
    "            import_dataset(datset, shuffle=True)\n",
    "        \n",
    "        print(orig_dims)\n",
    "        X_tr_orig = normalize_datapoints(X_tr_orig, 255.)\n",
    "        X_te_orig = normalize_datapoints(X_te_orig, 255.)\n",
    "        X_val_orig = normalize_datapoints(X_val_orig, 255.)\n",
    "        \n",
    "        (X_te_1, y_te_1) = apply_shift(X_te_orig, y_te_orig, shift, orig_dims, datset)   \n",
    "        \n",
    "        X_te_2 , y_te_2 = random_shuffle(X_te_1, y_te_1)\n",
    "        \n",
    "        # Check detection performance for different numbers of samples from test.\n",
    "        for si, sample in enumerate(samples):\n",
    "\n",
    "            print(\"Sample %s\" % sample)\n",
    "\n",
    "            sample_path = rand_run_path + str(sample) + '/'\n",
    "            if not os.path.exists(sample_path):\n",
    "                os.makedirs(sample_path)\n",
    "\n",
    "            X_te_3 = X_te_2[:sample,:]\n",
    "            y_te_3 = y_te_2[:sample]\n",
    "            \n",
    "            X_val_3 = X_val_orig[:sample,:]\n",
    "            y_val_3 = y_val_orig[:sample]\n",
    "            \n",
    "            X_tr_3 = np.copy(X_tr_orig)\n",
    "            y_tr_3 = np.copy(y_tr_orig)\n",
    "            \n",
    "            # Detect shift.\n",
    "            shift_detector = ShiftDetector(dr_techniques, test_types, od_tests, md_tests, sign_level, red_models,\n",
    "                                           sample, datset)\n",
    "#             (od_decs, ind_od_decs, ind_od_p_vals), \\\n",
    "#             (md_decs, ind_md_decs, ind_md_p_vals), \\\n",
    "            out_val_red, out_te_red, red_dim, red_models, val_acc, te_acc = shift_detector.detect_data_shift(X_tr_3, y_tr_3, X_val_3, y_val_3,\n",
    "                                                                                    X_te_3, y_te_3, orig_dims,\n",
    "                                                                                    nb_classes)\n",
    "            \n",
    "            \n",
    "            \n",
    "            out_val_red = {key:normalize_datapoints(out_val_red[key], 1./255.) for key in out_val_red.keys()}\n",
    "            out_te_red = {key:normalize_datapoints(out_te_red[key], 1./255.) for key in out_te_red.keys()}\n",
    "            val_file = 'val_mat_shift1_{}_{}_{}.mat'.format(shift,sample,rand_run)\n",
    "            test_file = 'test_mat_shift1_{}_{}_{}.mat'.format(shift,sample,rand_run)\n",
    "            \n",
    "            scipy.io.savemat(val_file, mdict=out_val_red, oned_as='row')\n",
    "            scipy.io.savemat(test_file, mdict=out_te_red, oned_as='row')\n",
    "            \n",
    "            \n",
    "#             print(\"Found pretrained model, loading...\")\n",
    "#             ckpt = torch.load(pretrained_filename)\n",
    "#             flow.load_state_dict(ckpt['state_dict'])\n",
    "#             result = ckpt.get(\"result\", None)\n",
    "            \n",
    "#             logp = flow._get_likelihood(sample_imgs, return_ll=True)\n",
    "#             logp = logp.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9b565-49f0-4e54-8489-7d4fcec318ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.loadmat(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853df4f6-5508-4892-91f4-603e28cc9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd16d5a-204d-4bc0-9b67-cbc09dd47da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a2160-9a11-4c96-a27e-9571855e2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img.png') #you can use any image you want.\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e717c0-f48e-4008-ad2b-8bf067985b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f94508-3188-4c28-a4f9-5b61d9713617",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue,green,red = cv2.split(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc63672-47b0-4a35-84c5-5c427cf2000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3cd38-3100-4187-8091-c0577404b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a0d50-9efb-4cbf-953d-1afb11a607f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_transformed = pca.fit_transform(red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cab972-1bcc-47e3-bce9-017f3e9e1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_inverted = pca.inverse_transform(red_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6be6be-cea3-433e-a69e-4f73f21ba3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_transformed = pca.fit_transform(green)\n",
    "green_inverted = pca.inverse_transform(green_transformed)\n",
    " \n",
    "#Applying to Blue channel and then applying inverse transform to transformed array.\n",
    "blue_transformed = pca.fit_transform(blue)\n",
    "blue_inverted = pca.inverse_transform(blue_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29055430-43f3-4cf7-9856-ffd2d712a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.inverse_transform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37107a9b-95d8-4945-85ab-240d07bbd000",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(red_inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a189d-1daf-4649-8af7-860c05d4ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(red_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2fa7d-61ae-4df9-8197-940f349601e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_compressed = (np.dstack((red_inverted, red_inverted, red_inverted))).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd77289-5811-4c1a-91ca-3b917ee0e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313784c-574e-4bda-a9c2-f17881f27b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
